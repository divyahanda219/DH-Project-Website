{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Inspect Ballon Trained Model\n",
    "\n",
    "Code and visualizations to test, debug, and evaluate the Mask R-CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "import Pig\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Path to Pig trained weights\n",
    "# You can download this file from the Releases page\n",
    "# https://github.com/matterport/Mask_RCNN/releases\n",
    "Pig_WEIGHTS_PATH = (\"C:\\Users\\dhanda\\Documents\\PhD\\Proj-1\\Maskrcnnd\\Pig\\logs\\pig20191128T1127\\mask_rcnn_pig_0030.h5\")  # TODO: update this path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Pig.PigConfig()\n",
    "Pig_DIR = os.path.join(ROOT_DIR, \"Pig/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation dataset\n",
    "dataset = Pig.PigDataset()\n",
    "dataset.load_Pig(Pig_DIR, \"val\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set path to Pig weights file\n",
    "\n",
    "# Download file from the Releases page and set its path\n",
    "# https://github.com/matterport/Mask_RCNN/releases\n",
    "# weights_path = \"/path/to/mask_rcnn_pig.h5\"\n",
    "\n",
    "# Or, load the last model you trained\n",
    "weights_path = model.find_last()\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture('Video_dir/Media1.mp4')  \n",
    "frame_count = 0\n",
    "frames = []\n",
    "batch_size= 1\n",
    "VIDEO_SAVE_DIR= ('Video_dir/output1/')\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    # Bail out when the video file ends\n",
    "    if not ret:\n",
    "        break        \n",
    "    # Save each frame of the video to a list\n",
    "    frame_count += 1\n",
    "    frames.append(frame)\n",
    "    print('frame_count :{0}'.format(frame_count))\n",
    "    if len(frames) == batch_size:\n",
    "        results = model.detect(frames, verbose=0)\n",
    "        print('Predicted')\n",
    "        for i, item in enumerate(zip(frames, results)):\n",
    "            frame = item[0]\n",
    "            r = item[1]\n",
    "            frame = visualize.display_instances(frame_count,\n",
    "                frame, r['rois'], r['masks'], r['class_ids'], dataset.class_names, r['scores']\n",
    "            )\n",
    "            name = '{0}.png'.format(frame_count + i - batch_size)\n",
    "            name = (VIDEO_SAVE_DIR + name)\n",
    "            #plt.savefig(name, dpi=600)\n",
    "            #cv2.imwrite(name, frame)\n",
    "            #print('writing to file:{0}'.format(name))\n",
    "        # Clear the frames array to start the next batch\n",
    "        frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image file paths to a list.\n",
    "import glob\n",
    "images = list(glob.iglob('Video_dir/output/*.jpg'))\n",
    "# Sort the images by name index.\n",
    "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('Video_dir/Media1.mp4');\n",
    "\n",
    "# Find OpenCV version\n",
    "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "if int(major_ver)  < 3 :\n",
    "    fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "    print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    "else :\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
    "\n",
    "video.release();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video(outvid, images=None, fps=10, size=None,\n",
    "               is_color=True, format=\"FMP4\"):\n",
    "    \"\"\"\n",
    "    Create a video from a list of images.\n",
    " \n",
    "    @param      outvid      output video\n",
    "    @param      images      list of images to use in the video\n",
    "    @param      fps         frame per second\n",
    "    @param      size        size of each frame\n",
    "    @param      is_color    color\n",
    "    @param      format      see http://www.fourcc.org/codecs.php\n",
    "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "    \"\"\"\n",
    "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
    "    fourcc = VideoWriter_fourcc(*format)\n",
    "    vid = None\n",
    "    for image in images:\n",
    "        if not os.path.exists(image):\n",
    "            raise FileNotFoundError(image)\n",
    "        img = imread(image)\n",
    "        if vid is None:\n",
    "            if size is None:\n",
    "                size = img.shape[1], img.shape[0]\n",
    "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
    "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
    "            img = resize(img, size)\n",
    "        vid.write(img)\n",
    "    vid.release()\n",
    "    return vid\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Directory of images to run detection on\n",
    "ROOT_DIR = os.getcwd()\n",
    "VIDEO_DIR = os.path.join(ROOT_DIR, \"videos\")\n",
    "VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, \"save\")\n",
    "images = list(glob.iglob('Video_dir/output1/*.jpg'))\n",
    "# Sort the images by integer index\n",
    "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n",
    "\n",
    "outvid = (\"VIDEO_DIR/out1.mp4\")\n",
    "make_video(outvid, images, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
    "import matplotlib.pyplot as plt\n",
    "#for image in images:\n",
    "img = plt.imread('Video_dir/output/1.jpg')\n",
    "img\n",
    "#cv2.imshow('image', img) \n",
    "    #size = img.shape[1], img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('videos/out.mp4')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
